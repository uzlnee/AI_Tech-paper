"# AI_Tech-paper" 


# 1. Introduction
NaverAIboostCamp에서 소개한 논문들을 주제별로 정리한 폴더입니다.
현재는 CV(Computer Vision) 트랙의 논문을 중심으로 정리하고 있으며, 추후 모든 트랙으로 확장할 예정입니다.

---
# 2에서 5까지는 논문만 있습니다.
- [6](#6-further-reading에-있었던-것들)부터 논문외의 사이트들을 정리하였습니다.
# 2. CV 트랙 정리(Only Paper)
## 2.1 CV 이론
- [VGGNet](https://arxiv.org/abs/1409.1556)  
- [ResNet](https://arxiv.org/abs/1512.03385)  
- [ViT](https://arxiv.org/abs/2010.11929)
- [Grad-CAM](https://arxiv.org/abs/1610.02391)
- [mixup](https://arxiv.org/abs/1710.09412)
- [CutMix](https://arxiv.org/abs/1905.04899)
- [Fully Convolutional Networks for Semantic Segmentation](https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Long_Fully_Convolutional_Networks_2015_CVPR_paper.pdf)
- [SAM](https://arxiv.org/pdf/2304.02643)
- [DETR](https://arxiv.org/pdf/2005.12872)
- [Real-World Single Image Super-Resolution: A New Benchmark and A New Model](https://arxiv.org/abs/1904.00523)
- [Real-World Blur Dataset for Learning and Benchmarking Deblurring Algorithms](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123700188.pdf)
- [Blind Super-Resolution Kernel Estimation using an Internal-GAN](https://arxiv.org/abs/1909.06581)
- [SpatialTracker: Tracking Any 2D Pixels in 3D Space](https://arxiv.org/abs/2404.04319)
- [CLIP huggingface implementation](https://github.com/huggingface/transformers/blob/main/src/transformers/models/clip/modeling_clip.py)
- [ImageBIND official implementation](https://github.com/facebookresearch/ImageBind)
- [LanguageBIND](https://arxiv.org/abs/2310.01852)
- [Flamingo pytorch implementation](https://github.com/lucidrains/flamingo-pytorch/blob/main/flamingo_pytorch/flamingo_pytorch.py)
- [LLaVA](https://llava-vl.github.io/)
- [BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation](https://arxiv.org/abs/2201.12086)
- [BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models](https://arxiv.org/abs/2301.12597)
- [DDPM](https://arxiv.org/abs/2006.11239)
- [LDM (Stable Diffusion)](https://arxiv.org/abs/2112.10752)
- [DDIM](https://arxiv.org/abs/2010.02502) 
- [3D MACHINE LEARNING](https://www.antoinetlc.com/blog-summary/3d-data-representations)
- [Mesh R-CNN](https://arxiv.org/abs/1906.02739)
- [NeRF](https://arxiv.org/abs/2003.08934)
- [3DGS](https://arxiv.org/abs/2308.04079)
- [DreamFusion](https://arxiv.org/abs/2209.14988)
- [Loper et al., SMPL: A Skinned Multi-Person Linear Model: SIGGRAPH 2015.](https://dl.acm.org/doi/10.1145/2816795.2818013)
- [Bogo et al., Keep it SMPL: Automatic Estimation of 3D Human Pose and Shape from a Single Image: ECCV 2016.](https://arxiv.org/abs/1607.08128)
- [Anguelov et al., SCAPE: Shape Completion and Animation of People: SIGGRAPH 2005.](https://dl.acm.org/doi/10.1145/1073204.1073207)


## 2.2 CV 기초 프로젝트
- [A survey on Image Data Augmentation for Deep Learning](https://journalofbigdata.springeropen.com/articles/10.1186/s40537-019-0197-0)
- [AutoAugment: Learning Augmentation Strategies from Data](https://arxiv.org/abs/1805.09501)
- [RandAugment: Practical automated data augmentation with a reduced search space](https://arxiv.org/abs/1909.13719)
- [Fine-Grained Image Analysis with Deep Learning: A Survey](https://arxiv.org/abs/2111.06119)
- [A ConvNet for the 2020s](https://arxiv.org/abs/2201.03545)
- [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929)
- [CoAtNet: Marrying Convolution and Attention for All Data Sizes](https://arxiv.org/abs/2106.04803)
- [ConViT: Improving Vision Transformers with Soft Convolutional Inductive Biases](https://arxiv.org/abs/2103.10697)
- [Multimodal Learning with Transformers: A Survey](https://arxiv.org/abs/2206.06488)
- [Self-supervised Learning: Generative or Contrastive](https://arxiv.org/abs/2006.08218)
- [Ensemble deep learning: A review](https://arxiv.org/abs/2104.02395)
  
## 2.3 Object Detection
- [R-CNN](https://arxiv.org/abs/1311.2524)
- [Fast R-CNN](https://arxiv.org/abs/1504.08083)
- [Faster R-CNN](https://arxiv.org/abs/1506.01497)
- [SPPNet](https://arxiv.org/abs/1406.4729)
- [FPN](https://arxiv.org/abs/1612.03144)
- [PAFPN](https://arxiv.org/abs/1803.01534)
- [DetectoRS](https://arxiv.org/abs/2006.02334)
- [EfficientDet (BiFPN)](https://arxiv.org/abs/1911.09070v7)
- [NasFPN](https://arxiv.org/abs/1904.07392)
- [AugFPN](https://arxiv.org/abs/1912.05384)
- [YOLO survey](https://arxiv.org/abs/2304.00501)
- [Retinanet (focal loss)](https://arxiv.org/abs/1708.02002)
- [SSD](https://arxiv.org/abs/1512.02325)
- [EfficientNet](https://arxiv.org/abs/1905.11946)
- [EfficientDet](https://arxiv.org/abs/1911.09070)
- [DCN](https://arxiv.org/abs/1703.06211)
- [DETR](https://arxiv.org/abs/2005.12872)
- [Swin](https://arxiv.org/abs/2103.14030)
- [YOLO v4](https://arxiv.org/abs/2004.10934)
- [M2Det](https://arxiv.org/abs/1811.04533)
- [CornerNet](https://arxiv.org/abs/1808.01244)

## 2.4 Data-Centric AI
- [DMLR](https://openreview.net/pdf?id=2kpu78QdeE)
- [Convolutional Character Networks](https://openaccess.thecvf.com/content_ICCV_2019/papers/Xing_Convolutional_Character_Networks_ICCV_2019_paper.pdf)
- [EAST](https://openaccess.thecvf.com/content_cvpr_2017/papers/Zhou_EAST_An_Efficient_CVPR_2017_paper.pdf)
- [Data and its (dis)contents: A survey of dataset development and use in machine learning research](https://www.sciencedirect.com/science/article/pii/S2666389921001847)
- [Human-In-The-Loop에 대한 survey 논문](https://www.sciencedirect.com/science/article/abs/pii/S0167739X22001790?casa_token=5poWCKizHjIAAAAA:Z8eK3GMWCCwOncUmdz2J8JHGNYAx3N4MW_31Uq3CnWVQN2C6RXXtOqc50GveYglcudc9TiwhYKk)
- [다양한 task에 적용 가능한 IAA에 관한 논문](https://dl.acm.org/doi/10.1145/3485447.3512242)
- [LLM을 활용한 data annotation에 관한 survey 논문](https://arxiv.org/abs/2402.13446)
- [A survey on Image Data Augmentation for Deep Learning](https://journalofbigdata.springeropen.com/articles/10.1186/s40537-019-0197-0)
- [A survey of synthetic data augmentation methods in computer vision](https://arxiv.org/abs/2403.10075)



## 2.5 Semantic Segmentation
- [FCN](https://arxiv.org/abs/1411.4038)
- [DeconvNet](https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Noh_Learning_Deconvolution_Network_ICCV_2015_paper.pdf)
- [SegNet](https://arxiv.org/pdf/1511.00561)
- [FCDenseNet](https://arxiv.org/pdf/1611.09326)
- [Unet](https://arxiv.org/abs/1505.04597)
- [DeepLabv1](https://arxiv.org/pdf/1412.7062)
- [DilatedNet ](https://arxiv.org/abs/1511.07122)
- [DeepLabv2](https://arxiv.org/pdf/1606.00915)
- [PSPNet](https://arxiv.org/pdf/1612.01105)
- [DeepLabv3](https://arxiv.org/pdf/1706.05587)
- [DeepLabv3+](https://arxiv.org/pdf/1802.02611)
- [Unet](https://arxiv.org/abs/1505.04597)
- [Unet++](https://arxiv.org/pdf/1912.05074)
- [Unet3+](https://arxiv.org/abs/2004.08790)
- [EfficientUnet](https://openaccess.thecvf.com/content_CVPRW_2020/papers/w22/Baheti_Eff-UNet_A_Novel_Architecture_for_Semantic_Segmentation_in_Unstructured_Environment_CVPRW_2020_paper.pdf)
- [DenseUnet](https://arxiv.org/abs/1611.09326)
- [ResidualUnet](https://arxiv.org/pdf/1711.10684)
- [SWA](https://arxiv.org/abs/1803.05407)
- [HRNet](https://arxiv.org/pdf/1908.07919)
- [SegFormer](https://arxiv.org/pdf/2105.15203)
- [ViT](https://arxiv.org/pdf/2010.11929)
- [Weakly Supervised Object Localization and Detection: A Survey](https://arxiv.org/abs/2104.07918)

# 3. NLP 트랙 정리(Only Paper)
## 3.1 NLP 이론
- [Distributed Representations of Words and Phrases and their Compositionality](https://arxiv.org/abs/1310.4546)
- [GloVe: Global Vectors for Word Representation](https://aclanthology.org/D14-1162/)
- [LSTM](https://direct.mit.edu/neco/article-abstract/9/8/1735/6109/Long-Short-Term-Memory?redirectedFrom=fulltext)
- [Highway Networks](https://arxiv.org/abs/1505.00387)
- [Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation](https://arxiv.org/abs/1406.1078)
- [Sequence to Sequence Learning with Neural Networks](https://arxiv.org/abs/1409.3215)
- [Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473)
- [Effective Approaches to Attention-based Neural Machine Translation](https://arxiv.org/abs/1508.04025)
- [Sparse is Enough in Scaling Transformers](https://openreview.net/pdf?id=-b5OSCydOMe)
- [Attention Is All You Need](https://arxiv.org/abs/1706.03762)
- [Layer Normalization](https://arxiv.org/abs/1607.06450)
- [Group Normalization](https://openaccess.thecvf.com/content_ECCV_2018/papers/Yuxin_Wu_Group_Normalization_ECCV_2018_paper.pdf)
- [Attention is not Explanation](https://arxiv.org/pdf/1902.10186)
- [Attention is not not Explanation](https://aclanthology.org/D19-1002.pdf)
- [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)
- [XLNet: Generalized Autoregressive Pretraining for Language Understanding](https://arxiv.org/abs/1906.08237)
- [Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation](https://arxiv.org/abs/1609.08144)
- [Neural Network Acceptability Judgments](https://arxiv.org/abs/1805.12471)
- [A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference](https://arxiv.org/abs/1704.05426)
- [SQuAD: 100,000+ Questions for Machine Comprehension of Text](https://arxiv.org/abs/1606.05250)
- [Hierarchical Neural Story Generation](https://arxiv.org/abs/1805.04833)
- [The Curious Case of Neural Text Degeneration](https://arxiv.org/abs/1904.09751)

  
## 3.2 NLP 기초 프로젝트
## 3.3 MRC
## 3.4 Data-Centric NLP
## 3.5 Generative for NLP


# 4. Recsys 트랙 정리(Only Paper)
## 4.1 Recsys 이론
## 4.2 ML 기초 프로젝트
## 4.3 Competitive DS
## 4.4 RecSys 기초프로젝트
## 4.5 Movie Rec



# 5. 공통 강의에서 소개한 논문 정리
## 5.1 Generative AI
- [LLM Survey 논문 (2023)](https://arxiv.org/abs/2303.18223)
- [GAN Survey 논문 (2020)](https://arxiv.org/abs/1906.01529)
- [Diffusion Models Survey 논문 (2024)](https://arxiv.org/abs/2209.00796)
- [RLHF 제안 논문](https://arxiv.org/abs/2203.02155)
- [Large Language Model 서베이 논문](https://arxiv.org/abs/2303.18223)
- [GPT-3 논문](https://arxiv.org/abs/2005.14165)
- [A Survey of Large Language Models](https://arxiv.org/abs/2303.18223)
- [Self-Instruct 논문](https://arxiv.org/abs/2212.10560)
- [Self-Rewarding 논문](https://arxiv.org/pdf/2401.10020)
- [GAN 논문](https://arxiv.org/abs/1406.2661)
- [cGAN 논문](https://arxiv.org/abs/1411.1784)
- [Pix2Pix 논문](https://arxiv.org/abs/1611.07004)
- [CycleGAN 논문](https://arxiv.org/abs/1703.10593)
- [StarGAN 논문](https://arxiv.org/abs/1711.09020)
- [ProgressiveGAN 논문](https://arxiv.org/abs/1710.10196)
- [StyleGAN 논문](https://arxiv.org/abs/1812.04948)
- [VAE 논문](https://arxiv.org/abs/1312.6114)
- [VQ-VAE 논문](https://arxiv.org/abs/1711.00937)
- [DDPM 논문](https://arxiv.org/abs/2006.11239)
- [DDIM 논문](https://arxiv.org/abs/2010.02502)
- [Classifier Guidance 논문](https://arxiv.org/abs/2105.05233)
- [Classifier-free Guidance 논문](https://arxiv.org/abs/2207.12598)
- [LDM 논문](https://arxiv.org/abs/2112.10752)
- [Latent Diffusion Model](https://arxiv.org/abs/2112.10752)
- [Stable Diffusion XL](https://arxiv.org/abs/2307.01952)
- [SDXL Turbo (Adversarial Diffusion Distillation)](https://arxiv.org/abs/2311.17042)




## 5.2 Product Serving
- paper 없음


## 5.3 최적화/경량화
- [Rethinking the Value of Network Pruning](https://arxiv.org/abs/1810.05270)
- [Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference](https://arxiv.org/abs/1712.05877)
- [The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks:](https://arxiv.org/abs/1803.03635)
- [Pruning Convolutional Neural Networks for Resource Efficient Inference](https://arxiv.org/abs/1611.06440)
- [Compressing BERT: Studying the Effects of Weight Pruning on Transfer Learning](https://arxiv.org/abs/2002.08307)
- [Distilling the Knowledge in a Neural Network](https://arxiv.org/abs/1503.02531)
- [Parameter-Efficient Transfer Learning for NLP ](https://arxiv.org/pdf/1902.00751)
- [Prompt tuning ](https://arxiv.org/pdf/2104.08691)
- [Prefix tuning ](https://arxiv.org/pdf/2101.00190)
- [AdapterFusion: Non-Destructive Task Composition for Transfer Learning](https://arxiv.org/abs/2005.00247)
- [QLoRA: Efficient Finetuning of Quantized LLMs](https://arxiv.org/abs/2305.14314)

---

**여기서부터는 논문외의 읽을거리들로 있었던 것들을 정리하였습니다.**
# 6. Further Reading에 있었던 것들.
## 6.1 공통코스
### 6.1.1 Pytorch
- [Introduction to PyTorch — PyTorch Tutorials documentation](https://pytorch.org/tutorials/beginner/introyt/introyt1_tutorial.html)
- [텐서(Tensor) — 파이토치 한국어 튜토리얼 (PyTorch tutorials in Korean)](https://tutorials.pytorch.kr/beginner/introyt/introyt1_tutorial.html)
- [torch.Tensor — PyTorch documentation](https://pytorch.org/docs/main/tensors.html)
- [부동소수점 - 백과사전](https://ko.wikipedia.org/wiki/%EB%B6%80%EB%8F%99%EC%86%8C%EC%88%98%EC%A0%90)
- [torch.randn — PyTorch documentation](https://pytorch.org/docs/stable/generated/torch.randn.html#torch.randn)
- [torch.Tensor — PyTorch documentation](https://pytorch.org/docs/main/tensors.html)
- [GPU와 AI - 네이버 지식백과](https://terms.naver.com/entry.naver?docId=2080143&cid=50305&categoryId=50305)
- [torch.Tensor.view — PyTorch main documentation](https://pytorch.org/docs/main/generated/torch.Tensor.view.html#torch-tensor-view)
- [torch.reshape — PyTorch main documentation](https://pytorch.org/docs/main/generated/torch.reshape.html#torch-reshape)
- [Difference between view, reshape, transpose and permute in PyTorch](https://jdhao.github.io/2019/07/10/pytorch_view_reshape_transpose_permute/)
- [torch.squeeze — PyTorch main documentation](https://pytorch.org/docs/main/generated/torch.squeeze.html#torch-squeeze)
- [Tensor 모양 설명](https://velog.io/@jk01019/broadcastto-repeat-repeatinterleave-view-reshape-expand-expandas-tile-flatten-unsqueeze-squeeze-stack-cat-d1n8ersb)
- [$L_p$ norm](https://en.m.wikipedia.org/wiki/Lp_space)
- [선형회귀](https://ko.wikipedia.org/wiki/%EC%84%A0%ED%98%95_%ED%9A%8C%EA%B7%80)
- [경사하강법 학습방법](https://www.youtube.com/watch?v=IHZwWFHWa-w)
- [Preprocessing data](https://scikit-learn.org/stable/modules/preprocessing.html)
- [PyTorch DataLoader — PyTorch main documentation](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)
- [BCELoss — PyTorch main documentation](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html#torch.nn.BCELoss)
- [BCEWithLogitsLoss — PyTorch main documentation](https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html#torch.nn.BCEWithLogitsLoss)
- [CrossEntropyLoss — PyTorch main documentation](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss)

### 6.1.2 ML LifeCycle
- [A survey on Image Data Augmentation for Deep Learning ](https://journalofbigdata.springeropen.com/articles/10.1186/s40537-019-0197-0) 
- [Clipping](https://arxiv.org/pdf/1211.5063) 
- [LSTM — PyTorch main documentation ](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html) 
- [Attention Is All You Need ](https://arxiv.org/pdf/1706.03762) 
- [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding ](https://arxiv.org/pdf/1810.04805) 
- [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale ](https://arxiv.org/pdf/2010.11929) 


### 6.1.3 EDA & DataViz
- [[Harvard Business Review] Boost Your Team’s Data Literacy](https://hbr.org/2020/02/boost-your-teams-data-literacy)
- [[Sequoia Capital] Why Data Science Matters](https://medium.com/sequoia-capital/why-data-science-matters-ee583f785a55)
- [[Sequoia Capital] Role of Data Scientist](https://medium.com/sequoia-capital/five-core-skills-of-a-data-scientist-fc044014fafa)
- [데이터 시각화 교과서 (클라우스 윌케 저)](https://clauswilke.com/dataviz/index.html)
- [Data Viz Project](https://datavizproject.com/)
- [Misleading Data Visualization](https://pressbooks.library.torontomu.ca/criticaldataliteracy/chapter/misleading-data-visualizations/)
- [[The Economists] Mistakes, we’ve drawn a few](https://medium.economist.com/mistakes-weve-drawn-a-few-8cdd8a42d368)
- [[Google ML Course] Types of Bias](https://developers.google.com/machine-learning/crash-course/fairness/types-of-bias?hl=ko)
- [[Github] Awesome Feature Engineering](https://github.com/aikho/awesome-feature-engineering)
- [[서울대 AI 연구원] 다차원 데이터 시각화와 AI (컴퓨터공학부 서진욱 교수)](https://www.youtube.com/watch?v=ymA1spEAd7M)
- [[Distill] How to Use t-SNE Effectively](https://distill.pub/2016/misread-tsne/)
- [Forecasting: Principles & Practice](https://otexts.com/fppkr/arima.html)
- [Hugging Face - NLP Course](https://huggingface.co/learn/nlp-course/ko/chapter1/2?fw=pt)
- [Text Visualization Browser](https://textvis.lnu.se/)
- [[Github] eugeneyan/applied-ml](https://github.com/eugeneyan/applied-ml)
- [[Material Design] Data Visualization](https://m2.material.io/design/communication/data-visualization.html)
- [잘못 사용된 시각화 모음 WTF.viz](https://viz.wtf/)
- [Startup Metrics for Pirates: AARRR! - Dave McClure](https://www.youtube.com/watch?v=irjgfW0BIrw)
- [데이터 시각화, 인지과학을 만나다 ](https://www.yes24.com/Product/Goods/19013968)
- [도널드 노만의 UX 디자인 특강 ](https://www.yes24.com/Product/Goods/59673763)
- [UX/UI의 10가지 심리학 법칙 ](https://product.kyobobook.co.kr/detail/S000212939982)

### 6.1.4 AI 개발 기초
- ["Clean Code: A Handbook of Agile Software Craftsmanship" by Robert C. Martin:](https://www.oreilly.com/library/view/clean-code-a/9780136083238/)
- ["Design Patterns: Elements of Reusable Object-Oriented Software" by Erich Gamma, Richard Helm, Ralph Johnson, and John Vlissidesn](https://www.oreilly.com/library/view/design-patterns-elements/0201633612/)
- ["모던 리눅스 교과서" by 마이클 하우센블라스](https://product.kyobobook.co.kr/detail/S000210138053)
- ["The Linux Command Line" by William Shotts:](https://wiki.lib.sun.ac.za/images/c/ca/TLCL-13.07.pdf)
- [Streamlit 공식 문서](https://docs.streamlit.io/)
- [Python 3.x Docs: Virtual Environments and Packages](https://docs.python.org/3/tutorial/venv.html)



## 6.2 CV
### 6.2.1 CV 이론   
- [한겨례 뉴스 “빌게이츠도 감탄한 최예진 교수, 생성형 AI 학습 데이터 공개해야"](https://www.hani.co.kr/arti/economy/economy_general/1128825.html)




### 6.2.2 CV 기초 프로젝트
- [Kaggle Competition](https://www.kaggle.com/competitions)
- [Image file format](https://en.wikipedia.org/wiki/Image_file_format)
- [Multilabel Image Classification Using Deep Learning](https://www.mathworks.com/help/deeplearning/ug/multilabel-image-classification-using-deep-learning.html)
- [Training with Pytorch](https://pytorch.org/tutorials/beginner/introyt/trainingyt.html)
- [Pytorch: Automatic Mixed Precision ](https://pytorch.org/tutorials/recipes/recipes/amp_recipe.html)
- [Nvidia: Mixed-Precision-Training](https://docs.nvidia.com/deeplearning/performance/mixed-precision-training/index.html)
- [Tensorboard](https://www.tensorflow.org/tensorboard/get_started?hl=ko)
- [WandB](https://wandb.ai/site/ko/)  

### 6.2.3 Object Detection
- [mmdetection github](https://github.com/open-mmlab/mmdetection)
- [detectron2 github](https://github.com/facebookresearch/detectron2)
- [Paperswithcode Object Detection](https://paperswithcode.com/task/object-detection)
- [Kaggle](https://www.kaggle.com/competitions)

### 6.2.4 Data-Centric AI
- [AI 최신 활용 사례](https://www.content.upstage.ai/blog/insight/examples-of-artificial-intelligence)
- [현실 세계에서의 데이터중심 AI](https://ko.upstage.ai/blog/tech/data-centric-ai-in-the-real-world)
- [SynthText in the Wild Dataset](https://www.robots.ox.ac.uk/~vgg/data/scenetext/)
- [Tesseract (Off-the-shelf OCR open source)](https://tesseract-ocr.github.io/)
- [Data annotation에 대한 OpenCV의 blogpost](https://opencv.org/blog/data-annotation/)


### 6.2.5 Semantic Segmentation
- [Segmentation models library](https://github.com/qubvel/segmentation_models)

## 6.3 NLP
### 6.3.1 NLP 이론
### 6.3.2 NLP 기초 프로젝트

### 6.3.3 MRC
### 6.3.4 Data-Centric NLP
### 6.3.5 Generative for NLP

## 6.4 Recsys
### 6.4.1 Recsys 이론
### 6.4.2 ML 기초 프로젝트
### 6.4.3 Competitive DS
### 6.4.4 RecSys 기초프로젝트
### 6.4.5 Movie Rec

## 6.5 Generative AI
- [LLM 모델 튜닝, 하나의 GPU로 가능할까? Parameter Efficient Fine-Tuning(PEFT)을 소개합니다!](https://devocean.sk.com/blog/techBoardDetail.do?ID=164779&boardType=techBlog)
- [Alpaca 홈페이지](https://crfm.stanford.edu/2023/03/13/alpaca.html)


## 6.6 Product Serving
- [Uber의 Michelangelo 플랫폼에 관한 글로, 대규모 머신러닝 모델 서빙 방법에 대한 통찰을 살펴볼 수 있습니다.](https://www.uber.com/en-KR/blog/scaling-michelangelo/)
- [Machine learning is going real-time](https://huyenchip.com/2020/12/27/real-time-machine-learning.html)
- [쏘카의 Airflow 구축기](https://tech.socarcorp.kr/data/2021/06/01/data-engineering-with-airflow.html)
- [쏘카의 Airflow 구축기2](https://tech.socarcorp.kr/data/2022/11/09/advanced-airflow-for-databiz.html)
- [버킷플레이스 Airflow 도입기](https://www.bucketplace.com/post/2021-04-13-%EB%B2%84%ED%82%B7%ED%94%8C%EB%A0%88%EC%9D%B4%EC%8A%A4-airflow-%EB%8F%84%EC%9E%85%EA%B8%B0/)
- [라인 엔지니어링 Airflow on Kubernetes](https://engineering.linecorp.com/ko/blog/data-engineering-with-airflow-k8s-1)
- [Day1, 2-2. 그런 REST API로 괜찮은가](https://www.youtube.com/watch?v=RP_f5dMoHFc)
- [HTTP response status codes](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [Advanced User Guide for FastAPI](https://fastapi.tiangolo.com/advanced/)
- [Awesome-fastapi](https://github.com/mjhea0/awesome-fastapi)
- [도커(Docker) 입문편: 컨테이너 기초부터 서버 배포까지](https://www.44bits.io/ko/post/easy-deploy-with-docker)
- [GCP 공식 문서](https://cloud.google.com/docs?_gl=1*1qvbnv0*_up*MQ..&gclid=CjwKCAiA9bq6BhAKEiwAH6bqoH2F6QSWY2FuBmbvo00dn9Q17vhlVZWt-IHvBB4JCmDoHUTjymDqQhoCnygQAvD_BwE&gclsrc=aw.ds&hl=ko)
- [AWS를 이용한 MLOps 구축 사례 살펴보기](https://aws.amazon.com/ko/blogs/tech/aws-mlops-use-case/)
- [MLOps Principles - Automation](https://ml-ops.org/content/mlops-principles#automation)
- [Experiments Tracking](https://ml-ops.org/content/mlops-principles#reproducibility)
- [Reproducibility](https://ml-ops.org/content/mlops-principles#reproducibility)
- [Data Engineer Jobs](https://www.linkedin.com/jobs/data-engineer-jobs/)

## 6.7 최적화/경량화
- [ Softmax Temperature](https://medium.com/@harshit158/softmax-temperature-5492e4007f71)
- [Lecture 10 - Knowledge Distillation | MIT 6.S965](https://www.youtube.com/watch?v=tT9Lnt6stwA)
- [ A brief overview of Imitation Learning](https://smartlabai.medium.com/a-brief-overview-of-imitation-learning-8a8a75c44a9c)
- [Dynamic Quantization](https://pytorch.org/tutorials/recipes/recipes/dynamic_quantization.html)
- [딥러닝의 Quantization (양자화)와 Quantization Aware Training:](https://gaussian37.github.io/dl-concept-quantization/#qat-quantization-aware-training-%EB%B0%A9%EB%B2%95-1)
- [Transfer Learning for Computer Vision Tutorial](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)
- [Brief Overview of Parallelism Strategies](https://afmck.in/posts/2023-02-26-parallelism/)
- [Data Parallelism on CNN:](https://siboehm.com/articles/22/data-parallel-training)
- [Pipeline Parallelism Algorithm](https://siboehm.com/articles/22/pipeline-parallel-training)
- [단일 머신을 사용한 모델 병렬화 모범 사례](https://tutorials.pytorch.kr/intermediate/model_parallel_tutorial.html)

# 7. Contribution 하는 방법

## 7.1 Fork를 한다.
- 원본 저장소를 내 계정으로 복사(Fork)

## 7.2 PR를 보낸다.
- Fork한 저장소에서 변경 내용을 작업한 뒤 Pull Request(Pull Request)를 생성

## 7.3 Approve를 받으면 Merge!
- 리뷰 후 승인을 받으면 원본 저장소에 변경사항이 병합(Merge)

>이 문서는 계속 업데이트 예정입니다.
궁금한 사항이나 제안이 있다면 Issue 혹은 Pull Request로 알려주세요!
감사합니다.
